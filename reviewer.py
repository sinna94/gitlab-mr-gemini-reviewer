import os
import requests
import sys
import subprocess
import tempfile
import json
import urllib.parse
import re
import ast
from pathlib import Path

gitlab_token = os.environ.get('GITLAB_TOKEN')
gitlab_project_id = os.environ.get('CI_PROJECT_ID')
gitlab_mr_iid = os.environ.get('CI_MERGE_REQUEST_IID')
gitlab_api_url = os.environ.get('CI_API_V4_URL', 'https://gitlab.com/api/v4')
gemini_api_key = os.environ.get('GEMINI_API_KEY')


def get_latest_commit_changes():
    """ìµœì‹  ì»¤ë°‹ì—ì„œ ë³€ê²½ëœ íŒŒì¼ë“¤ë§Œ ê°€ì ¸ì˜¤ê¸°"""
    # ìµœì‹  ì»¤ë°‹ SHA ê°€ì ¸ì˜¤ê¸°
    commits_url = f"{gitlab_api_url}/projects/{gitlab_project_id}/repository/commits"
    headers = {"PRIVATE-TOKEN": gitlab_token}

    # MRì˜ source branchì—ì„œ ìµœì‹  ì»¤ë°‹ ê°€ì ¸ì˜¤ê¸°
    mr_url = f"{gitlab_api_url}/projects/{gitlab_project_id}/merge_requests/{gitlab_mr_iid}"
    mr_resp = requests.get(mr_url, headers=headers)
    mr_resp.raise_for_status()
    mr_data = mr_resp.json()

    source_branch = mr_data['source_branch']

    # source branchì˜ ìµœì‹  ì»¤ë°‹ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    encoded_branch = urllib.parse.quote(source_branch, safe='')
    branch_url = f"{gitlab_api_url}/projects/{gitlab_project_id}/repository/branches/{encoded_branch}"
    branch_resp = requests.get(branch_url, headers=headers)
    branch_resp.raise_for_status()
    latest_commit_sha = branch_resp.json()['commit']['id']

    # ìµœì‹  ì»¤ë°‹ì˜ ë³€ê²½ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°
    commit_diff_url = f"{gitlab_api_url}/projects/{gitlab_project_id}/repository/commits/{latest_commit_sha}/diff"
    diff_resp = requests.get(commit_diff_url, headers=headers)
    diff_resp.raise_for_status()

    return diff_resp.json(), latest_commit_sha


def get_mr_changes_with_commits():
    """MR ì „ì²´ ë³€ê²½ì‚¬í•­ê³¼ ì»¤ë°‹ ì •ë³´ë¥¼ í•¨ê»˜ ê°€ì ¸ì˜¤ê¸°"""
    # MR ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    mr_url = f"{gitlab_api_url}/projects/{gitlab_project_id}/merge_requests/{gitlab_mr_iid}"
    headers = {"PRIVATE-TOKEN": gitlab_token}

    mr_resp = requests.get(mr_url, headers=headers)
    mr_resp.raise_for_status()
    mr_data = mr_resp.json()

    # MRì˜ ëª¨ë“  ì»¤ë°‹ ê°€ì ¸ì˜¤ê¸°
    commits_url = f"{gitlab_api_url}/projects/{gitlab_project_id}/merge_requests/{gitlab_mr_iid}/commits"
    commits_resp = requests.get(commits_url, headers=headers)
    commits_resp.raise_for_status()
    commits = commits_resp.json()

    # MR ì „ì²´ ë³€ê²½ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°
    changes_url = f"{gitlab_api_url}/projects/{gitlab_project_id}/merge_requests/{gitlab_mr_iid}/changes"
    changes_resp = requests.get(changes_url, headers=headers)
    changes_resp.raise_for_status()
    changes = changes_resp.json()['changes']

    return {
        'changes': changes,
        'commits': commits,
        'mr_info': mr_data,
        'latest_commit_sha': commits[0]['id'] if commits else None
    }

def get_reviewed_commits():
    """ì´ë¯¸ ë¦¬ë·°ëœ ì»¤ë°‹ë“¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    notes_url = f"{gitlab_api_url}/projects/{gitlab_project_id}/merge_requests/{gitlab_mr_iid}/notes"
    headers = {"PRIVATE-TOKEN": gitlab_token}

    try:
        resp = requests.get(notes_url, headers=headers)
        resp.raise_for_status()
        notes = resp.json()

        reviewed_commits = set()
        for note in notes:
            body = note.get('body', '')
            # ë¦¬ë·° ë§ˆì»¤ì—ì„œ ì»¤ë°‹ SHA ì¶”ì¶œ
            import re
            matches = re.findall(r'<!-- REVIEWED_COMMIT:([a-f0-9]+) -->', body)
            reviewed_commits.update(matches)

        return reviewed_commits
    except Exception as e:
        print(f"ê¸°ì¡´ ë¦¬ë·° í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return set()

def filter_new_changes(changes, commits, reviewed_commits):
    """ìƒˆë¡œìš´ ë³€ê²½ì‚¬í•­ë§Œ í•„í„°ë§"""
    if not reviewed_commits:
        return changes, commits

    # ìƒˆë¡œìš´ ì»¤ë°‹ë“¤ ì°¾ê¸°
    new_commits = [commit for commit in commits if commit['id'] not in reviewed_commits]

    if not new_commits:
        return [], []

    # ìƒˆë¡œìš´ ì»¤ë°‹ë“¤ì˜ ë³€ê²½ì‚¬í•­ë§Œ ì¶”ì¶œ
    new_changes = []
    new_commit_shas = {commit['id'] for commit in new_commits}

    # ê° ìƒˆë¡œìš´ ì»¤ë°‹ì˜ diff ê°€ì ¸ì˜¤ê¸°
    headers = {"PRIVATE-TOKEN": gitlab_token}

    for commit in new_commits:
        try:
            commit_diff_url = f"{gitlab_api_url}/projects/{gitlab_project_id}/repository/commits/{commit['id']}/diff"
            diff_resp = requests.get(commit_diff_url, headers=headers)
            diff_resp.raise_for_status()
            commit_changes = diff_resp.json()

            # ì»¤ë°‹ ì •ë³´ ì¶”ê°€
            for change in commit_changes:
                change['commit_sha'] = commit['id']
                change['commit_message'] = commit['message']
                change['commit_author'] = commit['author_name']

            new_changes.extend(commit_changes)
        except Exception as e:
            print(f"ì»¤ë°‹ {commit['id'][:8]} diff ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            continue

    return new_changes, new_commits

def group_changes_by_commit(changes):
    """ì»¤ë°‹ë³„ë¡œ ë³€ê²½ì‚¬í•­ ê·¸ë£¹í•‘"""
    commit_groups = {}

    for change in changes:
        commit_sha = change.get('commit_sha', 'unknown')
        if commit_sha not in commit_groups:
            commit_groups[commit_sha] = {
                'changes': [],
                'commit_info': {
                    'sha': commit_sha,
                    'message': change.get('commit_message', ''),
                    'author': change.get('commit_author', '')
                }
            }
        commit_groups[commit_sha]['changes'].append(change)

    return commit_groups

def should_review_incrementally(mr_info, commits):
    """ì ì§„ì  ë¦¬ë·°ë¥¼ í• ì§€ ì „ì²´ ë¦¬ë·°ë¥¼ í• ì§€ ê²°ì •"""
    # MRì´ ìƒˆë¡œ ìƒì„±ë˜ì—ˆê±°ë‚˜ ì²« ë¦¬ë·°ì¸ ê²½ìš° ì „ì²´ ë¦¬ë·°
    if mr_info.get('state') == 'opened' and len(commits) <= 3:
        return False

    # ì»¤ë°‹ì´ ë§ì€ ê²½ìš° ì ì§„ì  ë¦¬ë·°
    if len(commits) > 5:
        return True

    # ê¸°ë³¸ì ìœ¼ë¡œ ì ì§„ì  ë¦¬ë·°
    return True


def read_prompt(prompt_path):
    with open(prompt_path, 'r', encoding='utf-8') as f:
        return f.read().strip()


def review_with_gemini_cli(diff_text, prompt_text):
    """Gemini CLIë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë“œ ë¦¬ë·° ìƒì„±"""
    full_prompt = f"{prompt_text}\n\n{diff_text}"

    try:
        # Gemini CLIëŠ” GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©
        env = os.environ.copy()
        env['GEMINI_API_KEY'] = gemini_api_key

        # ì˜¬ë°”ë¥¸ Gemini CLI ëª…ë ¹ì–´ êµ¬ì¡°
        cmd = ['gemini', '--prompt', full_prompt]

        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8',
            timeout=120,
            env=env
        )

        if result.returncode == 0:
            return result.stdout.strip()
        else:
            error_msg = result.stderr.strip() if result.stderr else "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
            print(f"Gemini CLI ì˜¤ë¥˜ (ì¢…ë£Œ ì½”ë“œ {result.returncode}): {error_msg}")

            # í‘œì¤€ ì…ë ¥ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ì „ë‹¬ ì‹œë„
            try:
                print("í‘œì¤€ ì…ë ¥ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„ ì¤‘...")
                cmd_stdin = ['gemini']
                result_stdin = subprocess.run(
                    cmd_stdin,
                    input=full_prompt,
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    timeout=120,
                    env=env
                )

                if result_stdin.returncode == 0:
                    return result_stdin.stdout.strip()
                else:
                    return f"âŒ Gemini CLI ì‹¤í–‰ ì‹¤íŒ¨: {error_msg}"
            except Exception:
                return f"âŒ Gemini CLI ì‹¤í–‰ ì‹¤íŒ¨: {error_msg}"

    except subprocess.TimeoutExpired:
        print("Gemini CLI ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼")
        return "âŒ Gemini CLI ì‹¤í–‰ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
    except FileNotFoundError:
        print("Gemini CLIë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return "âŒ Gemini CLIê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    except Exception as e:
        print(f"Gemini CLI ì‹¤í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"


def post_mr_comment(body):
    url = f"{gitlab_api_url}/projects/{gitlab_project_id}/merge_requests/{gitlab_mr_iid}/notes"
    headers = {"PRIVATE-TOKEN": gitlab_token}
    data = {"body": body}
    resp = requests.post(url, headers=headers, data=data)
    resp.raise_for_status()
    return resp.json()


def has_been_reviewed_before(commit_sha):
    """ì´ì „ì— ë¦¬ë·°í–ˆë˜ ì»¤ë°‹ì¸ì§€ í™•ì¸"""
    # MRì˜ ê¸°ì¡´ ë…¸íŠ¸ë“¤ì„ í™•ì¸í•´ì„œ í•´ë‹¹ ì»¤ë°‹ì´ ì´ë¯¸ ë¦¬ë·°ë˜ì—ˆëŠ”ì§€ ì²´í¬
    notes_url = f"{gitlab_api_url}/projects/{gitlab_project_id}/merge_requests/{gitlab_mr_iid}/notes"
    headers = {"PRIVATE-TOKEN": gitlab_token}

    try:
        resp = requests.get(notes_url, headers=headers)
        resp.raise_for_status()
        notes = resp.json()

        # ì»¤ë°‹ SHAê°€ í¬í•¨ëœ ë¦¬ë·° ëŒ“ê¸€ì´ ìˆëŠ”ì§€ í™•ì¸
        review_marker = f"<!-- REVIEWED_COMMIT:{commit_sha} -->"
        for note in notes:
            if review_marker in note.get('body', ''):
                return True
        return False
    except:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ False ë°˜í™˜ (ìƒˆë¡œ ë¦¬ë·°)
        return False

def advanced_group_related_files(changes):
    """ê³ ê¸‰ íŒŒì¼ ê·¸ë£¹í•‘ - ì‚¬ìš© ê´€ê³„, í…ŒìŠ¤íŠ¸, ì„¤ì • íŒŒì¼ ë“±ì„ ëª¨ë‘ ê³ ë ¤"""
    groups = []
    processed = set()

    # íŒŒì¼ë³„ ë¶„ì„ ì •ë³´ ì €ì¥
    file_analysis = {}

    # 1ë‹¨ê³„: ëª¨ë“  íŒŒì¼ ë¶„ì„
    for change in changes:
        file_path = change.get('new_path') or change.get('old_path')
        if file_path:
            file_analysis[file_path] = analyze_file(change, file_path)

    # 2ë‹¨ê³„: ê´€ê³„ ë§¤í•‘ ìƒì„±
    relationships = build_relationship_map(file_analysis, changes)

    # 3ë‹¨ê³„: ê·¸ë£¹ ìƒì„±
    for change in changes:
        file_path = change.get('new_path') or change.get('old_path')
        if file_path in processed:
            continue

        # í•´ë‹¹ íŒŒì¼ê³¼ ê´€ë ¨ëœ ëª¨ë“  íŒŒì¼ ì°¾ê¸°
        related_files = find_all_related_files(file_path, relationships, changes)

        # ê·¸ë£¹ ìƒì„±
        group = create_file_group(file_path, related_files, file_analysis)
        groups.append(group)

        # ì²˜ë¦¬ëœ íŒŒì¼ë“¤ ë§ˆí‚¹
        for rf in related_files:
            processed.add(rf.get('new_path') or rf.get('old_path'))

    return groups

def detect_language(file_path):
    """íŒŒì¼ í™•ì¥ìë¡œ ì–¸ì–´ ê°ì§€"""
    if file_path.endswith('.java'):
        return 'java'
    elif file_path.endswith('.kt'):
        return 'kotlin'
    elif file_path.endswith('.py'):
        return 'python'
    elif file_path.endswith('.go'):
        return 'go'
    elif file_path.endswith(('.ts', '.tsx')):
        return 'typescript'
    elif file_path.endswith(('.js', '.jsx')):
        return 'javascript'
    elif file_path.endswith('.cs'):
        return 'csharp'
    elif file_path.endswith('.rb'):
        return 'ruby'
    elif file_path.endswith('.php'):
        return 'php'
    elif file_path.endswith(('.cpp', '.cc', '.cxx')):
        return 'cpp'
    elif file_path.endswith('.c'):
        return 'c'
    elif file_path.endswith('.rs'):
        return 'rust'
    elif file_path.endswith('.swift'):
        return 'swift'
    elif file_path.endswith('.scala'):
        return 'scala'
    else:
        return 'unknown'

def is_test_file(file_path):
    """í…ŒìŠ¤íŠ¸ íŒŒì¼ì¸ì§€ í™•ì¸"""
    path_lower = file_path.lower()

    # í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ íŒ¨í„´
    test_dirs = ['test/', 'tests/', '__test__/', '__tests__/', 'spec/', 'specs/']
    for test_dir in test_dirs:
        if test_dir in path_lower:
            return True

    # í…ŒìŠ¤íŠ¸ íŒŒì¼ëª… íŒ¨í„´
    test_patterns = [
        'test', 'tests', 'spec', 'specs', '_test', '_tests',
        '.test.', '.spec.', 'test_', 'spec_'
    ]

    for pattern in test_patterns:
        if pattern in path_lower:
            return True

    return False

def analyze_file(change, file_path):
    """íŒŒì¼ ë¶„ì„ - íƒ€ì…, ì˜ì¡´ì„±, ìš©ë„ ë“±"""
    analysis = {
        'type': determine_file_type(file_path),
        'language': detect_language(file_path),
        'imports': [],
        'exports': [],
        'classes': [],
        'functions': [],
        'is_test': is_test_file(file_path),
        'is_config': is_config_file(file_path),
        'is_doc': is_documentation_file(file_path),
        'dependencies': []
    }

    # diffì—ì„œ imports/exports ì¶”ì¶œ
    diff_content = change.get('diff', '')
    if diff_content:
        analysis.update(extract_dependencies_from_diff(diff_content, analysis['language']))

    return analysis

def determine_file_type(file_path):
    """íŒŒì¼ íƒ€ì… ê²°ì •"""
    path_lower = file_path.lower()

    if any(test_indicator in path_lower for test_indicator in ['test', 'spec', '__test__']):
        return 'test'
    elif any(config_indicator in path_lower for config_indicator in ['config', 'setting', 'env', 'properties']):
        return 'config'
    elif any(doc_indicator in path_lower for doc_indicator in ['readme', 'doc', 'md', 'rst']):
        return 'documentation'
    elif file_path.endswith(('.py', '.java', '.kt', '.ts', '.js', '.go', '.cs')):
        return 'source'
    elif file_path.endswith(('.json', '.yaml', '.yml', '.xml', '.toml')):
        return 'config'
    elif file_path.endswith(('.sql', '.migration')):
        return 'database'
    else:
        return 'other'

def is_config_file(file_path):
    """ì„¤ì • íŒŒì¼ ì—¬ë¶€ í™•ì¸"""
    config_patterns = [
        'config', 'setting', 'env', 'properties', 'application.yml',
        'application.yaml', 'application.properties', 'pom.xml',
        'build.gradle', 'package.json', 'requirements.txt', 'Dockerfile'
    ]
    return any(pattern in file_path.lower() for pattern in config_patterns)

def is_documentation_file(file_path):
    """ë¬¸ì„œ íŒŒì¼ ì—¬ë¶€ í™•ì¸"""
    return file_path.lower().endswith(('.md', '.rst', '.txt', '.adoc')) or 'readme' in file_path.lower()

def extract_dependencies_from_diff(diff_content, language):
    """diffì—ì„œ ì˜ì¡´ì„± ì¶”ì¶œ"""
    dependencies = {
        'imports': [],
        'exports': [],
        'classes': [],
        'functions': []
    }

    # ì¶”ê°€ëœ ë¼ì¸ë§Œ ë¶„ì„ (+ ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸)
    added_lines = [line[1:] for line in diff_content.split('\n') if line.startswith('+') and not line.startswith('+++')]

    for line in added_lines:
        line = line.strip()

        if language == 'python':
            # Python imports
            if line.startswith('import ') or line.startswith('from '):
                dependencies['imports'].append(line)
            # Python class/function definitions
            elif line.startswith('class '):
                match = re.match(r'class\s+(\w+)', line)
                if match:
                    dependencies['classes'].append(match.group(1))
            elif line.startswith('def '):
                match = re.match(r'def\s+(\w+)', line)
                if match:
                    dependencies['functions'].append(match.group(1))

        elif language in ['java', 'kotlin']:
            # Java/Kotlin imports
            if line.startswith('import '):
                dependencies['imports'].append(line)
            # Class definitions
            elif 'class ' in line:
                match = re.search(r'class\s+(\w+)', line)
                if match:
                    dependencies['classes'].append(match.group(1))

        elif language in ['javascript', 'typescript']:
            # JS/TS imports
            if line.startswith('import ') or 'require(' in line:
                dependencies['imports'].append(line)
            # Exports
            elif line.startswith('export '):
                dependencies['exports'].append(line)
            # Class/function definitions
            elif 'class ' in line:
                match = re.search(r'class\s+(\w+)', line)
                if match:
                    dependencies['classes'].append(match.group(1))

    return dependencies

def build_relationship_map(file_analysis, changes):
    """íŒŒì¼ ê°„ ê´€ê³„ ë§¤í•‘ ìƒì„±"""
    relationships = {}

    for file_path, analysis in file_analysis.items():
        relationships[file_path] = {
            'tests': [],
            'tested_by': [],
            'imports': [],
            'imported_by': [],
            'configs': [],
            'configured_by': [],
            'documents': [],
            'documented_by': []
        }

    # ê´€ê³„ ë¶„ì„
    for file_path, analysis in file_analysis.items():
        for other_path, other_analysis in file_analysis.items():
            if file_path == other_path:
                continue

            # í…ŒìŠ¤íŠ¸ ê´€ê³„
            if is_test_relationship(file_path, other_path, analysis, other_analysis):
                if analysis['is_test']:
                    relationships[file_path]['tests'].append(other_path)
                    relationships[other_path]['tested_by'].append(file_path)
                else:
                    relationships[file_path]['tested_by'].append(other_path)
                    relationships[other_path]['tests'].append(file_path)

            # import ê´€ê³„
            if is_import_relationship(file_path, other_path, analysis, other_analysis):
                relationships[file_path]['imports'].append(other_path)
                relationships[other_path]['imported_by'].append(file_path)

            # ì„¤ì • ê´€ê³„
            if is_config_relationship(file_path, other_path, analysis, other_analysis):
                if analysis['is_config']:
                    relationships[file_path]['configured_by'].append(other_path)
                    relationships[other_path]['configs'].append(file_path)
                else:
                    relationships[file_path]['configs'].append(other_path)
                    relationships[other_path]['configured_by'].append(file_path)

    return relationships

def is_test_relationship(file1, file2, analysis1, analysis2):
    """í…ŒìŠ¤íŠ¸ ê´€ê³„ ì—¬ë¶€ í™•ì¸"""
    # íŒŒì¼ëª… ê¸°ë°˜ ë§¤ì¹­
    base1 = Path(file1).stem.lower()
    base2 = Path(file2).stem.lower()

    # í…ŒìŠ¤íŠ¸ ì ‘ë¯¸ì‚¬/ì ‘ë‘ì‚¬ ì œê±°
    test_patterns = ['test', 'tests', 'spec', 'specs']
    for pattern in test_patterns:
        base1 = base1.replace(pattern, '')
        base2 = base2.replace(pattern, '')

    # í´ë˜ìŠ¤ëª… ë§¤ì¹­
    if analysis1['classes'] and analysis2['classes']:
        for class1 in analysis1['classes']:
            for class2 in analysis2['classes']:
                if class1.lower().replace('test', '') == class2.lower().replace('test', ''):
                    return True

    return base1 == base2

def is_import_relationship(file1, file2, analysis1, analysis2):
    """import ê´€ê³„ ì—¬ë¶€ í™•ì¸"""
    # íŒŒì¼ëª…ì´ import êµ¬ë¬¸ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
    file2_name = Path(file2).stem

    for import_line in analysis1['imports']:
        if file2_name.lower() in import_line.lower():
            return True

    return False

def is_config_relationship(file1, file2, analysis1, analysis2):
    """ì„¤ì • ê´€ê³„ ì—¬ë¶€ í™•ì¸"""
    # ì„¤ì • íŒŒì¼ê³¼ ì†ŒìŠ¤ íŒŒì¼ ê´€ê³„
    if analysis1['is_config'] and analysis2['type'] == 'source':
        return True
    elif analysis2['is_config'] and analysis1['type'] == 'source':
        return True

    return False

def find_all_related_files(file_path, relationships, changes):
    """íŒŒì¼ê³¼ ê´€ë ¨ëœ ëª¨ë“  íŒŒì¼ ì°¾ê¸°"""
    related_paths = set()

    # ì§ì ‘ ê´€ê³„
    for rel_type, related_list in relationships.get(file_path, {}).items():
        related_paths.update(related_list)

    # ê°„ì ‘ ê´€ê³„ (2ì°¨ ì—°ê²°)
    for related_path in list(related_paths):
        for rel_type, indirect_list in relationships.get(related_path, {}).items():
            if rel_type in ['tests', 'tested_by', 'imports', 'imported_by']:
                related_paths.update(indirect_list)

    # ë³€ê²½ëœ íŒŒì¼ë“¤ë§Œ í•„í„°ë§
    change_paths = {change.get('new_path') or change.get('old_path') for change in changes}
    related_paths = related_paths.intersection(change_paths)

    # Change ê°ì²´ ë°˜í™˜
    related_files = []
    for change in changes:
        change_path = change.get('new_path') or change.get('old_path')
        if change_path in related_paths or change_path == file_path:
            related_files.append(change)

    return related_files

def create_file_group(main_file, related_files, file_analysis):
    """íŒŒì¼ ê·¸ë£¹ ìƒì„±"""
    main_analysis = file_analysis.get(main_file, {})

    # ê·¸ë£¹ íƒ€ì… ê²°ì •
    file_types = [file_analysis.get(f.get('new_path') or f.get('old_path'), {}).get('type', 'other')
                  for f in related_files]

    has_test = 'test' in file_types
    has_source = 'source' in file_types
    has_config = 'config' in file_types
    has_doc = 'documentation' in file_types

    if has_test and has_source and has_config:
        group_type = 'comprehensive'
    elif has_test and has_source:
        group_type = 'source_with_test'
    elif has_source and has_config:
        group_type = 'source_with_config'
    elif has_test:
        group_type = 'test_only'
    elif has_config:
        group_type = 'config_only'
    elif has_doc:
        group_type = 'documentation_only'
    else:
        group_type = 'source_only'

    return {
        'type': group_type,
        'files': related_files,
        'main_file': main_file,
        'language': main_analysis.get('language', 'unknown'),
        'summary': create_group_summary(related_files, file_analysis)
    }

def create_group_summary(related_files, file_analysis):
    """ê·¸ë£¹ ìš”ì•½ ìƒì„±"""
    file_info = []
    for file_change in related_files:
        file_path = file_change.get('new_path') or file_change.get('old_path')
        analysis = file_analysis.get(file_path, {})
        file_info.append({
            'path': file_path,
            'type': analysis.get('type', 'unknown'),
            'classes': analysis.get('classes', []),
            'functions': analysis.get('functions', [])
        })

    return file_info

def main():
    try:
        # í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ì²´í¬
        if not all([gitlab_token, gitlab_project_id, gitlab_mr_iid, gemini_api_key]):
            missing_vars = []
            if not gitlab_token: missing_vars.append("GITLAB_TOKEN")
            if not gitlab_project_id: missing_vars.append("CI_PROJECT_ID")
            if not gitlab_mr_iid: missing_vars.append("CI_MERGE_REQUEST_IID")
            if not gemini_api_key: missing_vars.append("GEMINI_API_KEY")

            print(f"í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_vars)}")
            sys.exit(1)

        prompt_path = sys.argv[1] if len(sys.argv) > 1 else "prompt.txt"

        # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(prompt_path):
            print(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prompt_path}")
            sys.exit(1)

        prompt_text = read_prompt(prompt_path)

        # MR ì •ë³´ì™€ ë³€ê²½ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°
        try:
            mr_data = get_mr_changes_with_commits()
            all_changes = mr_data['changes']
            all_commits = mr_data['commits']
            mr_info = mr_data['mr_info']
            latest_commit_sha = mr_data['latest_commit_sha']
        except requests.exceptions.RequestException as e:
            print(f"GitLab API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            sys.exit(1)

        if not all_changes:
            print("ë¦¬ë·°í•  ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì´ë¯¸ ë¦¬ë·°ëœ ì»¤ë°‹ë“¤ í™•ì¸
        reviewed_commits = get_reviewed_commits()

        # ì ì§„ì  ë¦¬ë·° ì—¬ë¶€ ê²°ì •
        incremental_review = should_review_incrementally(mr_info, all_commits)

        if incremental_review and reviewed_commits:
            print(f"ì ì§„ì  ë¦¬ë·° ëª¨ë“œ: ì´ë¯¸ ë¦¬ë·°ëœ ì»¤ë°‹ {len(reviewed_commits)}ê°œ ì œì™¸")
            changes, new_commits = filter_new_changes(all_changes, all_commits, reviewed_commits)

            if not changes:
                print("ìƒˆë¡œìš´ ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ì»¤ë°‹ì´ ì´ë¯¸ ë¦¬ë·°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return

            print(f"ìƒˆë¡œìš´ ì»¤ë°‹ {len(new_commits)}ê°œì— ëŒ€í•´ ë¦¬ë·°ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.")

            # ì»¤ë°‹ë³„ë¡œ ë¦¬ë·° ì§„í–‰
            commit_groups = group_changes_by_commit(changes)

            for commit_sha, commit_group in commit_groups.items():
                if commit_sha == 'unknown':
                    continue

                commit_changes = commit_group['changes']
                commit_info = commit_group['commit_info']

                print(f"\nğŸ“ ì»¤ë°‹ {commit_sha[:8]} ë¦¬ë·° ì‹œì‘")
                print(f"   ë©”ì‹œì§€: {commit_info['message'][:50]}...")
                print(f"   ì‘ì„±ì: {commit_info['author']}")

                # íŒŒì¼ ê·¸ë£¹í•‘
                file_groups = advanced_group_related_files(commit_changes)

                for i, group in enumerate(file_groups, 1):
                    group_type = group['type']
                    main_file = group['main_file']
                    files = group['files']
                    summary = group['summary']

                    print(f"   ğŸ” [{i}/{len(file_groups)}] ë¦¬ë·° ì¤‘: {main_file} ({group_type})")

                    # diff ê²°í•©
                    combined_diff = ""
                    file_details = []

                    for file_change in files:
                        diff = file_change.get('diff')
                        if diff:
                            filename = file_change.get('new_path') or file_change.get('old_path', 'unknown')
                            file_details.append(filename)
                            combined_diff += f"\n### íŒŒì¼: {filename}\n{diff}\n"

                    if not combined_diff:
                        continue

                    # ì»¤ë°‹ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
                    context_info = f"""
ğŸ“‹ **ì»¤ë°‹ ì •ë³´**:
- ì»¤ë°‹ SHA: {commit_sha[:8]}
- ì»¤ë°‹ ë©”ì‹œì§€: {commit_info['message']}
- ì‘ì„±ì: {commit_info['author']}

ğŸ“‹ **íŒŒì¼ ê·¸ë£¹ ì •ë³´**:
- ê·¸ë£¹ íƒ€ì…: {group_type}
- í¬í•¨ íŒŒì¼: {', '.join(file_details)}
- ì£¼ìš” ì–¸ì–´: {group['language']}

ğŸ“Š **íŒŒì¼ë³„ ìƒì„¸**:
"""
                    for file_info in summary:
                        context_info += f"- `{file_info['path']}` ({file_info['type']})"
                        if file_info['classes']:
                            context_info += f" - í´ë˜ìŠ¤: {', '.join(file_info['classes'])}"
                        if file_info['functions']:
                            context_info += f" - í•¨ìˆ˜: {', '.join(file_info['functions'][:3])}"
                            if len(file_info['functions']) > 3:
                                context_info += f" (+{len(file_info['functions'])-3}ê°œ ë”)"
                        context_info += "\n"

                    full_prompt = f"{prompt_text}\n\n{context_info}\n\nìœ„ íŒŒì¼ë“¤ì€ ì„œë¡œ ì—°ê´€ëœ íŒŒì¼ ê·¸ë£¹ì…ë‹ˆë‹¤. ì¢…í•©ì ìœ¼ë¡œ ê²€í† í•´ì£¼ì„¸ìš”."

                    try:
                        success = post_combined_review(
                            combined_diff,
                            context_info,
                            prompt_text,
                            commit_sha,
                            group_type,
                            main_file
                        )
                        if success:
                            print(f"   âœ… {main_file} ê·¸ë£¹ ë¦¬ë·° ì™„ë£Œ")
                        else:
                            print(f"   âŒ {main_file} ê·¸ë£¹ ë¦¬ë·° ì‹¤íŒ¨")

                    except Exception as e:
                        print(f"   âŒ {main_file} ê·¸ë£¹ ë¦¬ë·° ì‹¤íŒ¨: {e}")
                        continue

        else:
            print("ì „ì²´ ë¦¬ë·° ëª¨ë“œ: MRì˜ ëª¨ë“  ë³€ê²½ì‚¬í•­ì„ ë¦¬ë·°í•©ë‹ˆë‹¤.")

            # ì „ì²´ íŒŒì¼ ê·¸ë£¹í•‘
            file_groups = advanced_group_related_files(all_changes)

            print(f"ğŸ“ MR {gitlab_mr_iid}ì˜ {len(file_groups)}ê°œ ë³µí•© ê·¸ë£¹ì— ëŒ€í•œ ì „ì²´ ë¦¬ë·°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

            for i, group in enumerate(file_groups, 1):
                group_type = group['type']
                main_file = group['main_file']
                files = group['files']
                summary = group['summary']

                print(f"ğŸ” [{i}/{len(file_groups)}] ë¦¬ë·° ì¤‘: {main_file} ({group_type})")

                # diff ê²°í•©
                combined_diff = ""
                file_details = []

                for file_change in files:
                    diff = file_change.get('diff')
                    if diff:
                        filename = file_change.get('new_path') or file_change.get('old_path', 'unknown')
                        file_details.append(filename)
                        combined_diff += f"\n### íŒŒì¼: {filename}\n{diff}\n"

                if not combined_diff:
                    continue

                # ì „ì²´ ë¦¬ë·° ì»¨í…ìŠ¤íŠ¸
                context_info = f"""
ğŸ“‹ **MR ì „ì²´ ë¦¬ë·°**:
- MR ë²ˆí˜¸: {gitlab_mr_iid}
- ì „ì²´ ì»¤ë°‹ ìˆ˜: {len(all_commits)}
- ê·¸ë£¹ íƒ€ì…: {group_type}
- í¬í•¨ íŒŒì¼: {', '.join(file_details)}
- ì£¼ìš” ì–¸ì–´: {group['language']}

ğŸ“Š **íŒŒì¼ë³„ ìƒì„¸**:
"""
                for file_info in summary:
                    context_info += f"- `{file_info['path']}` ({file_info['type']})"
                    if file_info['classes']:
                        context_info += f" - í´ë˜ìŠ¤: {', '.join(file_info['classes'])}"
                    if file_info['functions']:
                        context_info += f" - í•¨ìˆ˜: {', '.join(file_info['functions'][:3])}"
                        if len(file_info['functions']) > 3:
                            context_info += f" (+{len(file_info['functions'])-3}ê°œ ë”)"
                    context_info += "\n"

                try:
                    success = post_combined_review(
                        combined_diff,
                        context_info,
                        prompt_text,
                        latest_commit_sha,
                        group_type,
                        main_file
                    )
                    if success:
                        print(f"âœ… {main_file} ê·¸ë£¹ ë¦¬ë·° ì™„ë£Œ")
                    else:
                        print(f"âŒ {main_file} ê·¸ë£¹ ë¦¬ë·° ì‹¤íŒ¨")

                except Exception as e:
                    print(f"âŒ {main_file} ê·¸ë£¹ ë¦¬ë·° ì‹¤íŒ¨: {e}")
                    continue

        print("ğŸ‰ ëª¨ë“  ì½”ë“œ ë¦¬ë·°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"ğŸ’¥ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


def post_combined_review(combined_diff, context_info, prompt_text, commit_sha, group_type, main_file):
    """Gemini CLIë¡œ ë¦¬ë·°ë¥¼ ìƒì„±í•˜ê³  ì¸ë¼ì¸ ëŒ“ê¸€ë¡œ ì‘ì„±"""
    try:
        # Geminië¡œ ë¦¬ë·° ìƒì„±
        full_prompt = f"{prompt_text}\n\n{context_info}\n\nìœ„ íŒŒì¼ë“¤ì— ëŒ€í•´ êµ¬ì²´ì ì¸ ê°œì„ ì‚¬í•­ì„ íŒŒì¼ëª…ê³¼ ë¼ì¸ë²ˆí˜¸ë¥¼ í¬í•¨í•˜ì—¬ ì œì•ˆí•´ì£¼ì„¸ìš”. í˜•ì‹: íŒŒì¼ëª…:ë¼ì¸ë²ˆí˜¸ - ê°œì„ ì‚¬í•­"
        review = review_with_gemini_cli(combined_diff, full_prompt)

        # Gemini ë¦¬ë·°ì—ì„œ íŒŒì¼ë³„ ë¼ì¸ë³„ ëŒ“ê¸€ ì¶”ì¶œ
        inline_suggestions = parse_gemini_review_for_inline_comments(review, combined_diff)

        # ì¸ë¼ì¸ ëŒ“ê¸€ ì‘ì„±
        inline_count = 0

        for suggestion in inline_suggestions:
            try:
                post_inline_comment(
                    suggestion['file'],
                    suggestion['line'],
                    suggestion['message'],
                    commit_sha
                )
                inline_count += 1
            except Exception as e:
                print(f"ì¸ë¼ì¸ ëŒ“ê¸€ ì‘ì„± ì‹¤íŒ¨: {e}")
                continue

        # ë¦¬ë·° ì™„ë£Œ ë§ˆì»¤ë§Œ ì¶”ê°€ (ìˆ¨ê¹€ ëŒ“ê¸€)
        marker_comment = f"<!-- REVIEWED_COMMIT:{commit_sha} -->"
        post_mr_comment(marker_comment)

        if inline_count > 0:
            print(f"   ğŸ“ {inline_count}ê°œì˜ ì¸ë¼ì¸ ëŒ“ê¸€ ì¶”ê°€ (Gemini)")
        else:
            print(f"   âœ… íŠ¹ë³„í•œ ê°œì„ ì‚¬í•­ ì—†ìŒ")

        return True

    except Exception as e:
        print(f"ë¦¬ë·° ì‘ì„± ì‹¤íŒ¨: {e}")
        return False


def parse_gemini_review_for_inline_comments(review, combined_diff):
    """Gemini ë¦¬ë·°ì—ì„œ íŒŒì¼ë³„ ë¼ì¸ë³„ ëŒ“ê¸€ì„ ì¶”ì¶œí•˜ì—¬ ì¸ë¼ì¸ ëŒ“ê¸€ìš© ë°ì´í„°ë¡œ ë³€í™˜"""
    suggestions = []

    # diffì—ì„œ íŒŒì¼ë³„ ë¼ì¸ ì •ë³´ ë¯¸ë¦¬ ì¶”ì¶œ
    line_info = parse_diff_for_line_info(combined_diff)
    file_lines = {}
    for info in line_info:
        if info['file'] not in file_lines:
            file_lines[info['file']] = []
        file_lines[info['file']].append(info)

    lines = review.split('\n')

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # íŒŒì¼ëª…:ë¼ì¸ë²ˆí˜¸ í˜•íƒœ íŒ¨í„´ ì°¾ê¸°
        file_line_pattern = r'([^:]+):(\d+)\s*[-â€“]\s*(.+)'
        match = re.match(file_line_pattern, line)

        if match:
            file_path = match.group(1).strip()
            try:
                line_number = int(match.group(2))
                message = match.group(3).strip()

                # íŒŒì¼ ê²½ë¡œ ì •ê·œí™” (diffì—ì„œ ì¶”ì¶œí•œ íŒŒì¼ëª…ê³¼ ë§¤ì¹­)
                normalized_file = normalize_file_path(file_path, file_lines.keys())

                if normalized_file and message:
                    suggestions.append({
                        'file': normalized_file,
                        'line': line_number,
                        'message': f"ğŸ¤– **Gemini ì œì•ˆ**: {message}"
                    })
            except ValueError:
                continue

        # ë‹¤ë¥¸ íŒ¨í„´ë“¤ë„ ì‹œë„
        # "íŒŒì¼ëª…ì˜ ë¼ì¸ Xì—ì„œ..." í˜•íƒœ
        alt_pattern = r'([^ì˜]+)ì˜?\s*ë¼ì¸\s*(\d+)ì—ì„œ?\s*[:-]?\s*(.+)'
        alt_match = re.search(alt_pattern, line)

        if alt_match:
            file_path = alt_match.group(1).strip()
            try:
                line_number = int(alt_match.group(2))
                message = alt_match.group(3).strip()

                normalized_file = normalize_file_path(file_path, file_lines.keys())

                if normalized_file and message:
                    suggestions.append({
                        'file': normalized_file,
                        'line': line_number,
                        'message': f"ğŸ¤– **Gemini ì œì•ˆ**: {message}"
                    })
            except ValueError:
                continue

    # ì¤‘ë³µ ì œê±°
    unique_suggestions = []
    seen = set()
    for suggestion in suggestions:
        key = (suggestion['file'], suggestion['line'])
        if key not in seen:
            seen.add(key)
            unique_suggestions.append(suggestion)

    return unique_suggestions


def normalize_file_path(gemini_file_path, actual_file_paths):
    """Geminiê°€ ì–¸ê¸‰í•œ íŒŒì¼ ê²½ë¡œë¥¼ ì‹¤ì œ diffì˜ íŒŒì¼ ê²½ë¡œì™€ ë§¤ì¹­"""
    # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
    if gemini_file_path in actual_file_paths:
        return gemini_file_path

    # íŒŒì¼ëª…ë§Œ ë¹„êµ
    gemini_basename = os.path.basename(gemini_file_path)
    for actual_path in actual_file_paths:
        if os.path.basename(actual_path) == gemini_basename:
            return actual_path

    # ë¶€ë¶„ ë§¤ì¹­
    for actual_path in actual_file_paths:
        if gemini_file_path in actual_path or actual_path in gemini_file_path:
            return actual_path

    return None


def generate_smart_gemini_prompt(combined_diff, context_info):
    """ë” êµ¬ì²´ì ì¸ ì¸ë¼ì¸ ëŒ“ê¸€ì„ ìœ„í•œ Gemini í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    return f"""ë‹¤ìŒ ì½”ë“œ ë³€ê²½ì‚¬í•­ì„ ë¦¬ë·°í•˜ê³ , êµ¬ì²´ì ì¸ ê°œì„ ì‚¬í•­ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.

{context_info}

ì‘ë‹µ í˜•ì‹ì„ ë‹¤ìŒê³¼ ê°™ì´ í•´ì£¼ì„¸ìš”:
- ê° ê°œì„ ì‚¬í•­ì€ "íŒŒì¼ëª…:ë¼ì¸ë²ˆí˜¸ - ê°œì„ ì‚¬í•­ ì„¤ëª…" í˜•íƒœë¡œ ì‘ì„±
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆë§Œ í¬í•¨
- ì½”ë“œ í’ˆì§ˆ, ì„±ëŠ¥, ë³´ì•ˆ, ê°€ë…ì„± ê´€ì ì—ì„œ ê²€í† 
- ë¶ˆí•„ìš”í•œ ì„œë¡ ì´ë‚˜ ê²°ë¡  ì—†ì´ ê°œì„ ì‚¬í•­ë§Œ ë‚˜ì—´

ì˜ˆì‹œ:
src/main.py:15 - ë³€ìˆ˜ëª… 'data'ë¥¼ ë” êµ¬ì²´ì ì¸ ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”
utils/helper.js:23 - ì´ í•¨ìˆ˜ëŠ” ë„ˆë¬´ ê¸¸ì–´ì„œ ì—¬ëŸ¬ í•¨ìˆ˜ë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤

ì½”ë“œ ë³€ê²½ì‚¬í•­:
{combined_diff}"""


def post_inline_comment(file_path, line_number, comment_text, commit_sha):
    """íŠ¹ì • íŒŒì¼ì˜ ë¼ì¸ì— ì¸ë¼ì¸ ëŒ“ê¸€ì„ ë‹¬ê¸°"""
    url = f"{gitlab_api_url}/projects/{gitlab_project_id}/merge_requests/{gitlab_mr_iid}/notes"
    headers = {"PRIVATE-TOKEN": gitlab_token}

    # GitLab APIì˜ position íŒŒë¼ë¯¸í„° êµ¬ì„±
    position = {
        "base_sha": commit_sha,
        "start_sha": commit_sha,
        "head_sha": commit_sha,
        "old_path": file_path,
        "new_path": file_path,
        "position_type": "text",
        "new_line": line_number
    }

    data = {
        "body": comment_text,
        "position": json.dumps(position)
    }

    try:
        resp = requests.post(url, headers=headers, data=data)
        resp.raise_for_status()
        return resp.json()
    except requests.exceptions.HTTPError as e:
        print(f"ì¸ë¼ì¸ ëŒ“ê¸€ ìƒì„± ì‹¤íŒ¨ (íŒŒì¼: {file_path}, ë¼ì¸: {line_number}): {e}")
        # ì¸ë¼ì¸ ëŒ“ê¸€ ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ëŒ“ê¸€ë¡œ ëŒ€ì²´
        fallback_comment = f"**íŒŒì¼: `{file_path}` (ë¼ì¸ {line_number})**\n\n{comment_text}"
        return post_mr_comment(fallback_comment)


def parse_diff_for_line_info(diff_content):
    """diff ë‚´ìš©ì„ íŒŒì‹±í•˜ì—¬ ë³€ê²½ëœ ë¼ì¸ ì •ë³´ë¥¼ ì¶”ì¶œ"""
    lines_info = []
    current_file = None
    new_line_num = 0

    for line in diff_content.split('\n'):
        if line.startswith('diff --git'):
            # íŒŒì¼ëª… ì¶”ì¶œ
            parts = line.split(' ')
            if len(parts) >= 4:
                current_file = parts[3][2:]  # "b/" ì œê±°
        elif line.startswith('@@'):
            # ë¼ì¸ ë²ˆí˜¸ ì •ë³´ ì¶”ì¶œ (ì˜ˆ: @@ -1,4 +1,6 @@)
            match = re.search(r'\+(\d+)', line)
            if match:
                new_line_num = int(match.group(1)) - 1
        elif line.startswith('+') and not line.startswith('+++'):
            # ì¶”ê°€ëœ ë¼ì¸
            new_line_num += 1
            if current_file:
                lines_info.append({
                    'file': current_file,
                    'line': new_line_num,
                    'type': 'added',
                    'content': line[1:]  # '+' ì œê±°
                })
        elif line.startswith('-') and not line.startswith('---'):
            # ì‚­ì œëœ ë¼ì¸ (ë¼ì¸ ë²ˆí˜¸ëŠ” ì¦ê°€í•˜ì§€ ì•ŠìŒ)
            if current_file:
                lines_info.append({
                    'file': current_file,
                    'line': new_line_num,
                    'type': 'removed',
                    'content': line[1:]  # '-' ì œê±°
                })
        elif not line.startswith('\\'):
            # ë³€ê²½ë˜ì§€ ì•Šì€ ë¼ì¸
            new_line_num += 1

    return lines_info


if __name__ == "__main__":
    main()
